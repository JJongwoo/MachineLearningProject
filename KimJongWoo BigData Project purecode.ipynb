{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1991년부터 2017년까지의 데이터 수집\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "x_data = []\n",
    "pd_count=0\n",
    "start_year=1991\n",
    "x_pd = pd.DataFrame(columns=(\"score\", \"hit\", \"homerun\", \"fourball\", \"strikeout\", \"OPS\"))\n",
    "\n",
    "for w in range(23):\n",
    "    year=start_year+w\n",
    "    print(year)\n",
    "\n",
    "    url =\"http://www.statiz.co.kr/stat.php?opt=0&sopt=0&re=0&ys=\"+str(year)+\"&ye=\"+str(year)+\"&se=0&te=&tm=&ty=0&qu=auto&po=0&as=&ae=&hi=&un=&pl=&da=1&o1=WAR_ALL_ADJ&o2=TPA&de=1&lr=5&tr=&cv=&ml=1&sn=30&si=&cn=\"\n",
    "\n",
    "    # urlopen()으로 데이터 가져오기, 에러가 나도 진행하기위해 try, except문 사용\n",
    "    try:\n",
    "        res = req.urlopen(url)\n",
    "    except:\n",
    "        print(\"500\")\n",
    "        \n",
    "    # BeautifulSoup으로 분석하기 \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    \n",
    "    #페이지에서 보는 코드와 soup로 추출한 코드가 달라 직접 출력해서 태그를 체크했다.\n",
    "    #print(soup)\n",
    "    \n",
    "    # 원하는 데이터 추출하기 \n",
    "    a_list = soup.select(\"#mytable > tr\")\n",
    "    #print(len(a_list))\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    for a in a_list:\n",
    "        i = i+1\n",
    "        if i>7 and i<16:\n",
    "            #print(a)\n",
    "            b_list = a.select(\"td\")\n",
    "            #print(b_list)\n",
    "            j=0\n",
    "            for b in b_list:\n",
    "                j = j+1\n",
    "                #여러가지 데이터중 필요한 득점, 안타, 홈런, 볼넷, 삼진, OPS 정보를 얻기위한 코드이다.\n",
    "                if j==8 or j==9 or j==12 or j==17 or j==20 or j==27:\n",
    "                    c_list = b.select(\"font > span\")\n",
    "                    for c in c_list:\n",
    "                        #print(c.string)\n",
    "                        x_data.append(c.string+'.')\n",
    "                        if j==27:\n",
    "                            x_data[5] = x_data[5].split('.')[1] + '.';\n",
    "                    \n",
    "            #print(x_data)\n",
    "            x_pd.loc[pd_count] = [x_data[q] for q in range(6)]\n",
    "            pd_count = pd_count+1   \n",
    "            x_data=[]\n",
    "            \n",
    "#2014년 이후로는 페이지의 코드가 바뀌어 코드를 새로 작성했다.\n",
    "start_year = 2014\n",
    "for w in range(4):\n",
    "    year = start_year + w\n",
    "    print(year)\n",
    "    url =\"http://www.statiz.co.kr/stat.php?opt=0&sopt=0&re=0&ys=\"+str(year)+\"&ye=\"+str(year)+\"&se=0&te=&tm=&ty=0&qu=auto&po=0&as=&ae=&hi=&un=&pl=&da=1&o1=WAR_ALL_ADJ&o2=TPA&de=1&lr=5&tr=&cv=&ml=1&sn=30&si=&cn=\"\n",
    "\n",
    "    try:\n",
    "        res = req.urlopen(url)\n",
    "    except:\n",
    "        print(\"500\")\n",
    "        \n",
    "    # BeautifulSoup으로 분석하기 \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    \n",
    "    #페이지에서 보는 코드와 soup로 추출한 코드가 달라 직접 출력해서 태그를 체크했다.\n",
    "    #print(soup)\n",
    "    \n",
    "    # 원하는 데이터 추출하기 \n",
    "    a_list = soup.find_all(\"td\")\n",
    "\n",
    "    #print(a_list)\n",
    "    #print(len(a_list))\n",
    "    #print(a_list[38])\n",
    "    b = a_list[38].select(\"font > span\")[0].string\n",
    "    #print(a_list[69])#31차이\n",
    "\n",
    "    td_table = [38, 39, 42, 47, 50, 57]\n",
    "\n",
    "    i=0\n",
    "    for i in range(8):\n",
    "        j=0\n",
    "        for j in range(6):\n",
    "            b = a_list[td_table[j]+(i*31)].select(\"font > span\")[0].string\n",
    "            x_data.append(b+'.')\n",
    "            if j==5:\n",
    "                x_data[5] = x_data[5].split('.')[1]+'.'\n",
    "        \n",
    "        x_pd.loc[pd_count] = [x_data[q] for q in range(6)]\n",
    "        pd_count = pd_count+1\n",
    "        #print(x_data)\n",
    "        x_data=[]\n",
    "\n",
    "print(x_pd)\n",
    "\n",
    "#추출한 데이터로 작성한 DataFrame을 csv파일로 저장\n",
    "x_pd.to_csv(\"baseball_data.csv\", mode='w', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1991년부터 2012년까지의 데이터 수집\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "x_data = []\n",
    "pd_count=0\n",
    "start_year=1991\n",
    "x_pd = pd.DataFrame(columns=(\"score\", \"hit\", \"homerun\", \"fourball\", \"strikeout\", \"OPS\"))\n",
    "\n",
    "for w in range(22):\n",
    "    year=start_year+w\n",
    "    print(year)\n",
    "\n",
    "    url =\"http://www.statiz.co.kr/stat.php?opt=0&sopt=0&re=0&ys=\"+str(year)+\"&ye=\"+str(year)+\"&se=0&te=&tm=&ty=0&qu=auto&po=0&as=&ae=&hi=&un=&pl=&da=1&o1=WAR_ALL_ADJ&o2=TPA&de=1&lr=5&tr=&cv=&ml=1&sn=30&si=&cn=\"\n",
    "\n",
    "    # urlopen()으로 데이터 가져오기, 에러가 나도 진행하기위해 try, except문 사용\n",
    "    try:\n",
    "        res = req.urlopen(url)\n",
    "    except:\n",
    "        print(\"500\")\n",
    "        \n",
    "    # BeautifulSoup으로 분석하기 \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    \n",
    "    #페이지에서 보는 코드와 soup로 추출한 코드가 달라 직접 출력해서 태그를 체크했다.\n",
    "    #print(soup)\n",
    "    \n",
    "    # 원하는 데이터 추출하기 \n",
    "    a_list = soup.select(\"#mytable > tr\")\n",
    "    #print(len(a_list))\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    for a in a_list:\n",
    "        i = i+1\n",
    "        if i>7 and i<16:\n",
    "            #print(a)\n",
    "            b_list = a.select(\"td\")\n",
    "            #print(b_list)\n",
    "            j=0\n",
    "            for b in b_list:\n",
    "                j = j+1\n",
    "                #여러가지 데이터중 필요한 득점, 안타, 홈런, 볼넷, 삼진, OPS 정보를 얻기위한 코드이다.\n",
    "                if j==8 or j==9 or j==12 or j==17 or j==20 or j==27:\n",
    "                    c_list = b.select(\"font > span\")\n",
    "                    for c in c_list:\n",
    "                        #print(c.string)\n",
    "                        x_data.append(c.string+'.')\n",
    "                        if j==27:\n",
    "                            x_data[5] = x_data[5].split('.')[1] + '.';\n",
    "                    \n",
    "            #print(x_data)\n",
    "            x_pd.loc[pd_count] = [x_data[q] for q in range(6)]\n",
    "            pd_count = pd_count+1   \n",
    "            x_data=[]\n",
    "\n",
    "\n",
    "print(x_pd)\n",
    "\n",
    "#추출한 데이터로 작성한 DataFrame을 csv파일로 저장\n",
    "x_pd.to_csv(\"baseball_2012_data.csv\", mode='w', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1991년부터 2012년까지의 데이터 수집(삼진과 볼넷 제거, 타점과 war 추가)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "x_data = []\n",
    "pd_count=0\n",
    "start_year=1991\n",
    "x_pd = pd.DataFrame(columns=(\"war\", \"score\", \"hit\", \"homerun\", \"runbat\", \"OPS\"))\n",
    "\n",
    "for w in range(22):\n",
    "    year=start_year+w\n",
    "    print(year)\n",
    "\n",
    "    url =\"http://www.statiz.co.kr/stat.php?opt=0&sopt=0&re=0&ys=\"+str(year)+\"&ye=\"+str(year)+\"&se=0&te=&tm=&ty=0&qu=auto&po=0&as=&ae=&hi=&un=&pl=&da=1&o1=WAR_ALL_ADJ&o2=TPA&de=1&lr=5&tr=&cv=&ml=1&sn=30&si=&cn=\"\n",
    "\n",
    "    # urlopen()으로 데이터 가져오기, 에러가 나도 진행하기위해 try, except문 사용\n",
    "    try:\n",
    "        res = req.urlopen(url)\n",
    "    except:\n",
    "        print(\"500\")\n",
    "        \n",
    "    # BeautifulSoup으로 분석하기 \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    \n",
    "    #페이지에서 보는 코드와 soup로 추출한 코드가 달라 직접 출력해서 태그를 체크했다.\n",
    "    #print(soup)\n",
    "    \n",
    "    # 원하는 데이터 추출하기 \n",
    "    a_list = soup.select(\"#mytable > tr\")\n",
    "    #print(len(a_list))\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    for a in a_list:\n",
    "        i = i+1\n",
    "        #8개 구단 내에서의 정보\n",
    "        if i>7 and i<16:\n",
    "            #print(a)\n",
    "            b_list = a.select(\"td\")\n",
    "            #print(b_list)\n",
    "            j=0\n",
    "            for b in b_list:\n",
    "                j = j+1\n",
    "                #여러가지 데이터중 필요한 war, 득점, 안타, 홈런, 타점, OPS 정보를 얻기위한 코드이다.\n",
    "                if j==4 or j==8 or j==9 or j==12 or j==14 or j==27:\n",
    "                    c_list = b.select(\"font > span\")\n",
    "                    for c in c_list:\n",
    "                        #print(c.string)\n",
    "                        x_data.append(c.string)\n",
    "                        if j==27:\n",
    "                            x_data[5] = x_data[5].split('.')[1];\n",
    "                    \n",
    "            #print(x_data)\n",
    "            x_pd.loc[pd_count] = [x_data[q] for q in range(6)]\n",
    "            pd_count = pd_count+1   \n",
    "            x_data=[]\n",
    "\n",
    "\n",
    "print(x_pd)\n",
    "\n",
    "#추출한 데이터로 작성한 DataFrame을 csv파일로 저장\n",
    "x_pd.to_csv(\"baseball_2012_delete_strikeoutfourball_insert_runbatwar_data.csv\", mode='w', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보고서  1) 러닝\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "xy = np.loadtxt('baseball.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1000001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)\n",
    "    if step % 100000 == 0:\n",
    "        print(\"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보고서  2-1)러닝     읽어온 csv파일의 데이터를 정규화 후 러닝\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "#csv파일의 값들을 정규화하기 위한 함수 정의\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator/(denominator+1e-7)\n",
    "\n",
    "xy = np.loadtxt('baseball.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "#정규화!\n",
    "xy = MinMaxScaler(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(500001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)\n",
    "    if step % 100000 == 0:\n",
    "        print(\"\\nPrediction:\\n\", hy_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보고서  2-2)러닝  LearningRate와 러닝 횟수 조정\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('baseball.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#Learning_rate를 감소시켜서 cost값이 발산하지 않도록 조정\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00000005)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#러닝 횟수를 증가시켜서 충분히 러닝 진행\n",
    "for step in range(500001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)\n",
    "    if step % 100000 == 0:\n",
    "        print(\"\\nPrediction:\\n\", hy_val)\n",
    "    if step % 500000 == 0:\n",
    "        np.savetxt('predictedRate_data.csv', hy_val, delimiter=\",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보고서  3)러닝   새로 수집한 2012년까지의 데이터를 이용해 러닝\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  \n",
    "\n",
    "#새로운 데이터수집 코드로 수집한 데이터 파일을 이용\n",
    "xy = np.loadtxt('baseball_2012.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00000005)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(500001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)\n",
    "    if step % 100000 == 0:\n",
    "        print(\"\\nPrediction:\\n\", hy_val)\n",
    "    if step % 500000 == 0:\n",
    "        np.savetxt('predictedRate_data.csv', hy_val, delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 보고서  4) 러닝  x_data만 정규화 / 특징변수 삼진,볼넷 제거 및 타점, war 추가 / 러닝횟수 증가\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator/(denominator+1e-7)\n",
    "\n",
    "xy = np.loadtxt('baseball_2012_delete_strikeoutfourball_insert_runbatwar.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "y_data = xy[:, [-1]]\n",
    "xy=MinMaxScaler(xy)\n",
    "x_data = xy[:, 0:-1]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(800001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)\n",
    "    if step % 50000 == 0:\n",
    "        print(\"\\nPrediction:\\n\", hy_val)\n",
    "    if step % 800000 == 0:\n",
    "        np.savetxt('predictedRate_data.csv', hy_val, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
